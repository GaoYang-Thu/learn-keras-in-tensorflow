{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Not finished) Logistic regression in TensorFlow with eager mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logistic regression implemented using TensorFlow's Eager API\n",
    "* Author: Gao Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup eager mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling eager execution...\n",
      "Eager execution status: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "\n",
    "print('Enabling eager execution...')\n",
    "tfe.enable_eager_execution()\n",
    "\n",
    "print('Eager execution status: {}'.format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST dataset\n",
    "This example uses MNIST dataset. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1.  \n",
    "For simplicity, each image has streched and converted to an 1-D array of 28x28=784 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_mnist(file_path):\n",
    "    assert os.path.isfile(file_path)\n",
    "    data = np.load(file_path)\n",
    "    train_x,train_y = data['x_train'],data['y_train']\n",
    "    test_x,test_y = data['x_test'],data['y_test']\n",
    "    data.close()\n",
    "    return (train_x,train_y),(test_x,test_y)\n",
    "\n",
    "# mnist.npz was stored in local machine\n",
    "mnist_path = '/Users/Yang/Projects/aymericdamien-tensorflow-examples/notebooks/7_MyCode/mnist.npz'\n",
    "\n",
    "# load numpy arries from mnist.npz\n",
    "(train_x_raw,train_y),(test_x_raw,test_y) = load_mnist(mnist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x_raw.reshape(60000, 28*28)\n",
    "\n",
    "test_x = test_x_raw.reshape(10000, 28*28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "W = tfe.Variable(tf.zeros([784,10]), name = 'Weights')\n",
    "b = tfe.Variable(tf.zeros([10]), name = 'bias')\n",
    "\n",
    "def model(inputs):\n",
    "    return tf.matmul(inputs, W) + b\n",
    "\n",
    "def loss(model, inputs, labels):\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits = model(inputs), labels = labels))\n",
    "\n",
    "def accuracy_fn(model, inputs, labels):\n",
    "    prediction = tf.nn.softmax(model(inputs))\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), labels)\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, float32))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "grad = tfe.implicit_gradients(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
