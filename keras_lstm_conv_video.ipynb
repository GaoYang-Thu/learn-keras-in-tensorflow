{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate video by convolutional LSTM network using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicts next frame of the video contains moving squares\n",
    "* Author: Gao Yang\n",
    "* Note:\n",
    "    * 40 minutes per epoch on Intel i5 CPU (12000 minutes for 300 epochs, too long!)\n",
    "    * 2.5 minutes per epoch on Tesla K80 (Floydhub)\n",
    "    * ? seconds per epoch on Titan (Lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate artificial movie\n",
    "* noisy_movies: x_train\n",
    "* shifted_movies: y_train\n",
    "* 3 to 7 moving squares inside\n",
    "* 1x1 or 2x2 pixels each\n",
    "* moving linearly\n",
    "* first create movie with bigger size=80x80 then crop it to 40x40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movies(num_sample=1200, num_frame=15):\n",
    "    \n",
    "    row = 80\n",
    "    col = 80\n",
    "    \n",
    "    noisy_movies = np.zeros((num_sample, num_frame, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = noisy_movies\n",
    "    \n",
    "    for i in range(num_sample):\n",
    "        \n",
    "        # add squares\n",
    "        n = np.random.randint(3,8)\n",
    "        \n",
    "        for j in range(n):\n",
    "            # initial position\n",
    "            x_start = np.random.randint(20,60)\n",
    "            y_start = np.random.randint(20,60)\n",
    "            \n",
    "            # direction\n",
    "            x_direction = np.random.randint(0,3) - 1 # [-1,0,1]\n",
    "            y_direction = np.random.randint(0,3) - 1\n",
    "            \n",
    "            # size\n",
    "            size_square = np.random.randint(2,4)\n",
    "            \n",
    "            for index_frame in range(num_frame):\n",
    "                \n",
    "                # label the positions of squares on each frame\n",
    "                x_shift = x_start + x_direction * index_frame\n",
    "                y_shift = y_start + y_direction * index_frame\n",
    "                \n",
    "                noisy_movies[i, index_frame, \n",
    "                            x_shift - size_square:x_shift + size_square,\n",
    "                            y_shift - size_square:y_shift + size_square, 0] += 1\n",
    "                \n",
    "                # add noise\n",
    "                if np.random.randint(0,2):\n",
    "                    noise_f = (-1)**np.random.randint(0,2)\n",
    "                    noisy_movies[i, index_frame,\n",
    "                                x_shift - size_square - 1:x_shift + size_square + 1,\n",
    "                                y_shift - size_square - 1:y_shift + size_square + 1, 0] += noise_f * 0.2\n",
    "                \n",
    "                # shift the ground truth by 1\n",
    "                x_shift = x_start + x_direction * (index_frame + 1)\n",
    "                y_shift = y_start + y_direction * (index_frame + 1)\n",
    "                shifted_movies[i, index_frame, \n",
    "                              x_shift - size_square:x_shift + size_square,\n",
    "                              y_shift - size_square:y_shift + size_square, 0] += 1\n",
    "    \n",
    "    # crop to 40x40\n",
    "    noisy_movies = noisy_movies[:,:,20:60,20:60,:]\n",
    "    shifted_movies = shifted_movies[:,:,20:60,20:60,:]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    \n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "# generate videos\n",
    "noisy_movies, shifted_movies = generate_movies()\n",
    "\n",
    "print('Videos are generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build LSTM conv network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 40, kernel_size = (3,3),\n",
    "                    input_shape = (None,40,40,1),\n",
    "                    padding = 'same', return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 40, kernel_size = (3,3),\n",
    "                    padding = 'same', return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 40, kernel_size = (3,3),\n",
    "                    padding = 'same', return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 40, kernel_size = (3,3),\n",
    "                    padding = 'same', return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv3D(filters = 1, kernel_size = (3,3,3),\n",
    "                    activation = 'sigmoid',\n",
    "                    padding = 'same', data_format = 'channels_last'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model on GPU (Floydhub or Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adadelta')\n",
    "\n",
    "\n",
    "model.fit(noisy_movies[:1000], shifted_movies[:1000],\n",
    "         batch_size = 10,\n",
    "         epochs = 300, # Total time for 72 epochs: 72*2.5=180min=3hr\n",
    "         verbose = 1,\n",
    "         validation_split = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model (Only execute this cell when using Floydhub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training is done\n",
    "# !mkdir keras_lstm_conv_video\n",
    "## save weights\n",
    "# model.save_weights('./keras_lstm_conv_video/model_lstm_conv_weights.h5')\n",
    "## then download the weights.h5 from floydhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model (Only execute this cell when using Local GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training is done\n",
    "!mkdir keras_lstm_conv_video\n",
    "# save weights\n",
    "model.save_weights('./keras_lstm_conv_video/model_lstm_conv_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload the model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_pwd = '/Users/Yang/Projects/keras-examples/keras_lstm_conv_video/'\n",
    "from keras.models import load_model\n",
    "\n",
    "model.load_weights(working_pwd + 'model_lstm_conv_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model on a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mov = 1004\n",
    "track = noisy_movies[example_mov][:7,::,::,::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_position = model.predict(track[np.newaxis,::,::,::,::], verbose = 1)\n",
    "    new = new_position[::,-1,::,::,::]\n",
    "    track = np.concatenate((track,new), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then compare the predictions with the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track2 = noisy_movies[example_mov][::,::,::,::]\n",
    "\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize = (10,5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    \n",
    "    if i >= 7:\n",
    "        ax.text(1,3,'Predictions!', fontsize = 20, color = 'w')\n",
    "    else:\n",
    "        ax.text(1,3,'Initial Trajactory', fontsize = 20, color = 'w')\n",
    "    \n",
    "    toplot = track[i,:,:,0]\n",
    "    plt.imshow(toplot)\n",
    "    \n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1,3,'Ground Truth', fontsize = 20, color = 'w')\n",
    "    \n",
    "    toplot = track2[i,:,:,0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[example_mov][i - 1,:,:,0]\n",
    "    \n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig(working_pwd + '{:03d}_animate.png'.format(i + 1))\n",
    "    print('Image {:03d} : animation finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
